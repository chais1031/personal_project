{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Contextural Bias of ResNet50 on CIFAR10 Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "This notebook trains and tests a vanilla ResNet50 model and a stylised ResNet50 model with the CIFAR10 dataset. It includes functions for loading the dataset, turning them into tensors, model training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn import Conv2d, AvgPool2d\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "import os\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading\n",
    "\n",
    "The following cell provides a class that loads the CIFAR dataset given the relevant path, processes it into a dictionary format of class labels and content then processes the images into tensors. The class also has helper functions to extract information about the dataset needed for model training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CifarDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, data_path):\n",
    "        \n",
    "        super(CifarDataset, self).__init__()\n",
    "        self.data_path = data_path\n",
    "        self.num_classes = 0\n",
    "        self.classes = []\n",
    "        \n",
    "        classes_list = []\n",
    "        for class_name in os.listdir(data_path):\n",
    "            if not os.path.isdir(os.path.join(data_path,class_name)):\n",
    "                continue\n",
    "            classes_list.append(class_name)\n",
    "        classes_list.sort()\n",
    "        self.classes = [dict(class_idx = k, class_name = v) for k, v in enumerate(classes_list)]\n",
    "        \n",
    "\n",
    "        self.num_classes = len(self.classes)\n",
    "\n",
    "        self.image_list = []\n",
    "        for cls in self.classes:\n",
    "            class_path = os.path.join(data_path, cls['class_name'])\n",
    "            for image_name in os.listdir(class_path):\n",
    "                image_path = os.path.join(class_path, image_name)\n",
    "                self.image_list.append(dict(\n",
    "                    cls = cls,\n",
    "                    image_path = image_path,\n",
    "                    image_name = image_name,\n",
    "                ))\n",
    "\n",
    "        self.img_idxes = np.arange(0,len(self.image_list))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_idxes)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        img_idx = self.img_idxes[index]\n",
    "        img_info = self.image_list[img_idx]\n",
    "\n",
    "        img = Image.open(img_info['image_path'])\n",
    "\n",
    "        tr = transforms.ToTensor()\n",
    "        img = tr(img)\n",
    "        tr = transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "        img = tr(img)\n",
    "        return dict(image = img, cls = img_info['cls']['class_idx'], class_name = img_info['cls']['class_name'])\n",
    "\n",
    "    def get_number_of_classes(self):\n",
    "        return self.num_classes\n",
    "\n",
    "    def get_number_of_samples(self):\n",
    "        return self.__len__()\n",
    "\n",
    "    def get_class_names(self):\n",
    "        return [cls['class_name'] for cls in self.classes]\n",
    "\n",
    "    def get_class_name(self, class_idx):\n",
    "        return self.classes[class_idx]['class_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cifar_datasets(data_path):\n",
    "    dataset = CifarDataset(data_path)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data being used for this experiment are normal CIFAR10 dataset and the stylised version of the CIFAR10 dataset created using AdaIN style transfer.\n",
    "\n",
    "The following cell calls the function created above to load the training, validation and testing datasets of both normal and stylised CIFAR10 and transforms them into data loaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train samples 36000\n",
      "Class names are: ['0000000001', '0000000010', '0000000100', '0000001000', '0000010000', '0000100000', '0001000000', '0010000000', '0100000000', '1000000000']\n",
      "Number of val samples 4000\n",
      "Class names are: ['0000000001', '0000000010', '0000000100', '0000001000', '0000010000', '0000100000', '0001000000', '0010000000', '0100000000', '1000000000']\n",
      "Number of test samples 10000\n",
      "Class names are: ['0000000001', '0000000010', '0000000100', '0000001000', '0000010000', '0000100000', '0001000000', '0010000000', '0100000000', '1000000000']\n"
     ]
    }
   ],
   "source": [
    "# Load normal CIFAR10\n",
    "data_path_train = \"../../CIFAR/cifar32/training\"\n",
    "dataset_train = get_cifar_datasets(data_path_train)\n",
    "\n",
    "data_path_val = \"../../CIFAR/cifar32/validation/\"\n",
    "dataset_val = get_cifar_datasets(data_path_val)\n",
    "\n",
    "data_path_test = \"../../CIFAR/cifar32/testing/\"\n",
    "dataset_test = get_cifar_datasets(data_path_test)\n",
    "\n",
    "print(f\"Number of train samples {dataset_train.__len__()}\")\n",
    "print(\"Class names are: \" + str(dataset_train.get_class_names()))\n",
    "\n",
    "print(f\"Number of val samples {dataset_val.__len__()}\")\n",
    "print(\"Class names are: \" + str(dataset_val.get_class_names()))\n",
    "\n",
    "print(f\"Number of test samples {dataset_test.__len__()}\")\n",
    "print(\"Class names are: \" + str(dataset_test.get_class_names()))\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "data_loader_train = DataLoader(dataset_train, BATCH_SIZE, shuffle = True)\n",
    "data_loader_val = DataLoader(dataset_val, BATCH_SIZE, shuffle = True)\n",
    "data_loader_test = DataLoader(dataset_test, BATCH_SIZE, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stylised train samples 216000\n",
      "Class names are: ['0000000001', '0000000010', '0000000100', '0000001000', '0000010000', '0000100000', '0001000000', '0010000000', '0100000000', '1000000000']\n",
      "Number of stylised val samples 4000\n",
      "Class names are: ['0000000001', '0000000010', '0000000100', '0000001000', '0000010000', '0000100000', '0001000000', '0010000000', '0100000000', '1000000000']\n",
      "Number of stylised test samples 10000\n",
      "Class names are: ['0000000001', '0000000010', '0000000100', '0000001000', '0000010000', '0000100000', '0001000000', '0010000000', '0100000000', '1000000000']\n"
     ]
    }
   ],
   "source": [
    "# Load stylised CIFAR10 with original kaggle images\n",
    "data_path_train_style = \"../../CIFAR/cifar32_style/training\"\n",
    "dataset_train_style = get_cifar_datasets(data_path_train_style)\n",
    "\n",
    "data_path_val_style = \"../../CIFAR/cifar32_style/validation/\"\n",
    "dataset_val_style = get_cifar_datasets(data_path_val_style)\n",
    "\n",
    "data_path_test_style = \"../../CIFAR/cifar32_style/testing/\"\n",
    "dataset_test_style = get_cifar_datasets(data_path_test_style)\n",
    "\n",
    "print(f\"Number of stylised train samples {dataset_train_style.__len__()}\")\n",
    "print(\"Class names are: \" + str(dataset_train_style.get_class_names()))\n",
    "\n",
    "print(f\"Number of stylised val samples {dataset_val_style.__len__()}\")\n",
    "print(\"Class names are: \" + str(dataset_val_style.get_class_names()))\n",
    "\n",
    "print(f\"Number of stylised test samples {dataset_test_style.__len__()}\")\n",
    "print(\"Class names are: \" + str(dataset_test_style.get_class_names()))\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "data_loader_train_style = DataLoader(dataset_train_style, BATCH_SIZE, shuffle = True)\n",
    "data_loader_val_style = DataLoader(dataset_val_style, BATCH_SIZE, shuffle = True)\n",
    "data_loader_test_style = DataLoader(dataset_test_style, BATCH_SIZE, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reduced stylised train samples 216000\n",
      "Class names are: ['0000000001', '0000000010', '0000000100', '0000001000', '0000010000', '0000100000', '0001000000', '0010000000', '0100000000', '1000000000']\n",
      "Number of reduced stylised val samples 4000\n",
      "Class names are: ['0000000001', '0000000010', '0000000100', '0000001000', '0000010000', '0000100000', '0001000000', '0010000000', '0100000000', '1000000000']\n",
      "Number of reduced stylised test samples 10000\n",
      "Class names are: ['0000000001', '0000000010', '0000000100', '0000001000', '0000010000', '0000100000', '0001000000', '0010000000', '0100000000', '1000000000']\n"
     ]
    }
   ],
   "source": [
    "# Load stylised CIFAR10 with reduced kaggle images\n",
    "data_path_train_style_red = \"../../CIFAR/cifar32_style_red/training\"\n",
    "dataset_train_style_red = get_cifar_datasets(data_path_train_style_red)\n",
    "\n",
    "data_path_val_style_red = \"../../CIFAR/cifar32_style_red/validation/\"\n",
    "dataset_val_style_red = get_cifar_datasets(data_path_val_style_red)\n",
    "\n",
    "data_path_test_style_red = \"../../CIFAR/cifar32_style_red/testing/\"\n",
    "dataset_test_style_red = get_cifar_datasets(data_path_test_style_red)\n",
    "\n",
    "print(f\"Number of reduced stylised train samples {dataset_train_style_red.__len__()}\")\n",
    "print(\"Class names are: \" + str(dataset_train_style_red.get_class_names()))\n",
    "\n",
    "print(f\"Number of reduced stylised val samples {dataset_val_style_red.__len__()}\")\n",
    "print(\"Class names are: \" + str(dataset_val_style_red.get_class_names()))\n",
    "\n",
    "print(f\"Number of reduced stylised test samples {dataset_test_style_red.__len__()}\")\n",
    "print(\"Class names are: \" + str(dataset_test_style_red.get_class_names()))\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "data_loader_train_style_red = DataLoader(dataset_train_style_red, BATCH_SIZE, shuffle = True)\n",
    "data_loader_val_style_red = DataLoader(dataset_val_style_red, BATCH_SIZE, shuffle = True)\n",
    "data_loader_test_style_red = DataLoader(dataset_test_style_red, BATCH_SIZE, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of batch['image'] torch.Size([64, 3, 32, 32])\n",
      "Shape of batch['cls'] torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Delete before submission\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(4,4, figsize=(8, 8))\n",
    "\n",
    "for batch in data_loader_train_style:\n",
    "\n",
    "    print(f\"Shape of batch['image'] {batch['image'].shape}\")\n",
    "    print(f\"Shape of batch['cls'] {batch['cls'].shape}\")\n",
    "\n",
    "    for i in range(BATCH_SIZE):\n",
    "        col = i % 4\n",
    "        row = i // 4\n",
    "\n",
    "        img = batch['image'][i].numpy()\n",
    "\n",
    "        axes[row,col].set_axis_off()\n",
    "        axes[row,col].set_title(batch['class_name'][i])\n",
    "        axes[row,col].imshow(np.transpose(img,(1,2,0)))\n",
    "                         \n",
    "        if i >= 15:\n",
    "            break\n",
    "\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining ResNet50\n",
    "\n",
    "The following code defines Resnet50 architecture that will be used to train and test the CIFAR dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define resnet building blocks\n",
    "class ResidualBlock(nn.Module): \n",
    "    expansion = 4\n",
    "    \n",
    "    def __init__(self, inchannel, outchannel, stride=1): \n",
    "        \n",
    "        super(ResidualBlock, self).__init__() \n",
    "        \n",
    "        self.left = nn.Sequential(\n",
    "            Conv2d(inchannel, outchannel, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(outchannel),\n",
    "            nn.ReLU(inplace=True),\n",
    "            Conv2d(outchannel, outchannel, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(outchannel),\n",
    "            nn.ReLU(inplace=True),\n",
    "            Conv2d(outchannel, self.expansion*outchannel, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(self.expansion*outchannel)\n",
    "        ) \n",
    "        \n",
    "        self.shortcut = nn.Sequential()\n",
    "        \n",
    "        if stride != 1 or inchannel != self.expansion*outchannel: \n",
    "            self.shortcut = nn.Sequential(\n",
    "                Conv2d(inchannel, self.expansion*outchannel, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*outchannel)\n",
    "            ) \n",
    "            \n",
    "    def forward(self, x): \n",
    "        out = self.left(x) \n",
    "        out += self.shortcut(x) \n",
    "        out = F.relu(out) \n",
    "        return out\n",
    "\n",
    "    \n",
    "# define resnet\n",
    "class ResNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, ResidualBlock, num_classes = 10):\n",
    "        \n",
    "        super(ResNet, self).__init__()\n",
    "        \n",
    "        self.inchannel = 64\n",
    "        self.conv1 = nn.Sequential(\n",
    "            Conv2d(3, 64, kernel_size = 3, stride = 1,padding = 1, bias = False),\n",
    "            nn.BatchNorm2d(64), \n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layer1 = self.make_layer(ResidualBlock, 64, 3, stride = 1)\n",
    "        self.layer2 = self.make_layer(ResidualBlock, 128, 4, stride = 2)\n",
    "        self.layer3 = self.make_layer(ResidualBlock, 256, 6, stride = 2)\n",
    "        self.layer4 = self.make_layer(ResidualBlock, 512, 3, stride = 2)\n",
    "        self.avgpool = AvgPool2d(4)\n",
    "        self.fc = nn.Linear(512*ResidualBlock.expansion, num_classes)\n",
    "        \n",
    "    \n",
    "    def make_layer(self, block, channels, num_blocks, stride):\n",
    "        \n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        \n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.inchannel, channels, stride))\n",
    "            self.inchannel = channels * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "def ResNet50():\n",
    "    return ResNet(ResidualBlock)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following are the training, validation and testing functions for the experiment. train_part() function trains and updates gradients on each batch of the training set and once that is done, it tests its accuracy on the validation set. Every time the validation test returns a better accuracy than the current maximum, the model is saved and carries on with the next epoch. Then it checks with the learning reate scheduler for any changes in learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "    \n",
    "print_every = 100\n",
    "def check_accuracy(loader, model):\n",
    "    # function for test accuracy on validation and test set\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(loader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs = batch['image'].to(device)\n",
    "            labels = batch['cls'].to(device)\n",
    "            scores = model(inputs)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == labels).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct, accuracy of the dataset is: %.3f %%' % (num_correct, num_samples, 100 * acc))\n",
    "\n",
    "\n",
    "def train_part(model, train_data, val_data, model_path, optimizer, lr_scheduler, epochs=1):\n",
    "    model.to(device)\n",
    "    val_acc = 0\n",
    "    num_epoch = 2\n",
    "    # Main Loop\n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "        val_loss = 0\n",
    "        running_loss = 0\n",
    "\n",
    "        # Training Loop\n",
    "        for i, batch in enumerate(train_data, 0):\n",
    "            # set model to training mode\n",
    "            model.train()\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs = batch['image'].to(device)\n",
    "            labels = batch['cls'].to(device)\n",
    "\n",
    "            # get outputs from the input data and calculate the cross entropy loss\n",
    "            scores = model(inputs)\n",
    "            loss = F.cross_entropy(scores, labels)\n",
    "\n",
    "            # zero and update the gradients and optimise\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 200 == 199:    # print every 200 mini-batches\n",
    "                print('[%d, %5d] loss: %.6f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 200))\n",
    "                running_loss = 0.0\n",
    "\n",
    "        # set model to evaluation mode\n",
    "        model.eval()\n",
    "\n",
    "        # Validation Loop\n",
    "        with torch.no_grad():\n",
    "            num_correct = 0\n",
    "            num_samples = 0\n",
    "            for i, batch in enumerate(val_data, 0):\n",
    "                # get the inputs; data is a list of [inputs, labels]\n",
    "                inputs = batch['image'].to(device)\n",
    "                labels = batch['cls'].to(device)\n",
    "\n",
    "                # get the outputs from the model\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                # compute accuracy based on the outputs\n",
    "                _, preds = outputs.max(1)\n",
    "                num_correct += (preds == labels).sum()\n",
    "                num_samples += preds.size(0)\n",
    "            acc = float(num_correct) / num_samples\n",
    "            print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
    "\n",
    "            if acc > val_acc:\n",
    "                print('saving model')\n",
    "                torch.save(model.state_dict(), model_path)\n",
    "                val_acc = acc\n",
    "            else:\n",
    "                print('skip model saving')\n",
    "        lr_scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla ResNet50 Training\n",
    "\n",
    "The model used in this experiment is ResNet50 with Adam optimiser with learning rate scheduler and default settings. Learning rate changes every 80, 120, 160, 180th epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   200] loss: 4.404325\n",
      "[1,   400] loss: 2.024682\n",
      "Got 1102 / 4000 correct (27.55)\n",
      "saving model\n",
      "[2,   200] loss: 1.832623\n",
      "[2,   400] loss: 1.778489\n",
      "Got 1357 / 4000 correct (33.92)\n",
      "saving model\n",
      "[3,   200] loss: 1.682013\n",
      "[3,   400] loss: 1.644374\n",
      "Got 1742 / 4000 correct (43.55)\n",
      "saving model\n",
      "[4,   200] loss: 1.536639\n",
      "[4,   400] loss: 1.519283\n",
      "Got 1905 / 4000 correct (47.62)\n",
      "saving model\n",
      "[5,   200] loss: 1.424567\n",
      "[5,   400] loss: 1.381319\n",
      "Got 1950 / 4000 correct (48.75)\n",
      "saving model\n",
      "[6,   200] loss: 1.306095\n",
      "[6,   400] loss: 1.299620\n",
      "Got 2101 / 4000 correct (52.52)\n",
      "saving model\n",
      "[7,   200] loss: 1.238209\n",
      "[7,   400] loss: 1.209562\n",
      "Got 2297 / 4000 correct (57.43)\n",
      "saving model\n",
      "[8,   200] loss: 1.158139\n",
      "[8,   400] loss: 1.128885\n",
      "Got 2319 / 4000 correct (57.98)\n",
      "saving model\n",
      "[9,   200] loss: 1.071163\n",
      "[9,   400] loss: 1.066281\n",
      "Got 2395 / 4000 correct (59.88)\n",
      "saving model\n",
      "[10,   200] loss: 1.002524\n",
      "[10,   400] loss: 0.994455\n",
      "Got 2517 / 4000 correct (62.92)\n",
      "saving model\n",
      "[11,   200] loss: 0.939792\n",
      "[11,   400] loss: 0.941422\n",
      "Got 2483 / 4000 correct (62.08)\n",
      "skip model saving\n",
      "[12,   200] loss: 0.872660\n",
      "[12,   400] loss: 0.884309\n",
      "Got 2590 / 4000 correct (64.75)\n",
      "saving model\n",
      "[13,   200] loss: 0.796673\n",
      "[13,   400] loss: 0.811469\n",
      "Got 2715 / 4000 correct (67.88)\n",
      "saving model\n",
      "[14,   200] loss: 0.736872\n",
      "[14,   400] loss: 0.775851\n",
      "Got 2819 / 4000 correct (70.47)\n",
      "saving model\n",
      "[15,   200] loss: 0.703507\n",
      "[15,   400] loss: 0.704217\n",
      "Got 2838 / 4000 correct (70.95)\n",
      "saving model\n",
      "[16,   200] loss: 0.661027\n",
      "[16,   400] loss: 0.660169\n",
      "Got 2729 / 4000 correct (68.23)\n",
      "skip model saving\n",
      "[17,   200] loss: 0.593846\n",
      "[17,   400] loss: 0.604538\n",
      "Got 2853 / 4000 correct (71.33)\n",
      "saving model\n",
      "[18,   200] loss: 0.519474\n",
      "[18,   400] loss: 0.572367\n",
      "Got 2830 / 4000 correct (70.75)\n",
      "skip model saving\n",
      "[19,   200] loss: 0.483870\n",
      "[19,   400] loss: 0.521207\n",
      "Got 2928 / 4000 correct (73.20)\n",
      "saving model\n",
      "[20,   200] loss: 0.432769\n",
      "[20,   400] loss: 0.458289\n",
      "Got 2934 / 4000 correct (73.35)\n",
      "saving model\n",
      "[21,   200] loss: 0.380177\n",
      "[21,   400] loss: 0.427378\n",
      "Got 2997 / 4000 correct (74.92)\n",
      "saving model\n",
      "[22,   200] loss: 0.349307\n",
      "[22,   400] loss: 0.373460\n",
      "Got 2890 / 4000 correct (72.25)\n",
      "skip model saving\n",
      "[23,   200] loss: 0.312420\n",
      "[23,   400] loss: 0.345527\n",
      "Got 3042 / 4000 correct (76.05)\n",
      "saving model\n",
      "[24,   200] loss: 0.245569\n",
      "[24,   400] loss: 0.324636\n",
      "Got 3101 / 4000 correct (77.53)\n",
      "saving model\n",
      "[25,   200] loss: 0.246393\n",
      "[25,   400] loss: 0.283761\n",
      "Got 3092 / 4000 correct (77.30)\n",
      "skip model saving\n",
      "[26,   200] loss: 0.201688\n",
      "[26,   400] loss: 0.237687\n",
      "Got 3019 / 4000 correct (75.48)\n",
      "skip model saving\n",
      "[27,   200] loss: 0.178474\n",
      "[27,   400] loss: 0.226283\n",
      "Got 2974 / 4000 correct (74.35)\n",
      "skip model saving\n",
      "[28,   200] loss: 0.164259\n",
      "[28,   400] loss: 0.197268\n",
      "Got 2950 / 4000 correct (73.75)\n",
      "skip model saving\n",
      "[29,   200] loss: 0.150031\n",
      "[29,   400] loss: 0.190129\n",
      "Got 3089 / 4000 correct (77.22)\n",
      "skip model saving\n",
      "[30,   200] loss: 0.143414\n",
      "[30,   400] loss: 0.173839\n",
      "Got 2999 / 4000 correct (74.98)\n",
      "skip model saving\n",
      "[31,   200] loss: 0.142438\n",
      "[31,   400] loss: 0.147751\n",
      "Got 3156 / 4000 correct (78.90)\n",
      "saving model\n",
      "[32,   200] loss: 0.116120\n",
      "[32,   400] loss: 0.152966\n",
      "Got 3024 / 4000 correct (75.60)\n",
      "skip model saving\n",
      "[33,   200] loss: 0.124552\n",
      "[33,   400] loss: 0.153579\n",
      "Got 3059 / 4000 correct (76.48)\n",
      "skip model saving\n",
      "[34,   200] loss: 0.129410\n",
      "[34,   400] loss: 0.105105\n",
      "Got 3097 / 4000 correct (77.42)\n",
      "skip model saving\n",
      "[35,   200] loss: 0.101993\n",
      "[35,   400] loss: 0.115131\n",
      "Got 3086 / 4000 correct (77.15)\n",
      "skip model saving\n",
      "[36,   200] loss: 0.099225\n",
      "[36,   400] loss: 0.111868\n",
      "Got 3052 / 4000 correct (76.30)\n",
      "skip model saving\n",
      "[37,   200] loss: 0.127439\n",
      "[37,   400] loss: 0.112409\n",
      "Got 3084 / 4000 correct (77.10)\n",
      "skip model saving\n",
      "[38,   200] loss: 0.080614\n",
      "[38,   400] loss: 0.093930\n",
      "Got 3114 / 4000 correct (77.85)\n",
      "skip model saving\n",
      "[39,   200] loss: 0.074455\n",
      "[39,   400] loss: 0.133886\n",
      "Got 3109 / 4000 correct (77.72)\n",
      "skip model saving\n",
      "[40,   200] loss: 0.075840\n",
      "[40,   400] loss: 0.096302\n",
      "Got 3112 / 4000 correct (77.80)\n",
      "skip model saving\n",
      "[41,   200] loss: 0.103431\n",
      "[41,   400] loss: 0.106453\n",
      "Got 3082 / 4000 correct (77.05)\n",
      "skip model saving\n",
      "[42,   200] loss: 0.069354\n",
      "[42,   400] loss: 0.085238\n",
      "Got 3075 / 4000 correct (76.88)\n",
      "skip model saving\n",
      "[43,   200] loss: 0.079888\n",
      "[43,   400] loss: 0.086720\n",
      "Got 3122 / 4000 correct (78.05)\n",
      "skip model saving\n",
      "[44,   200] loss: 0.087012\n",
      "[44,   400] loss: 0.105792\n",
      "Got 3137 / 4000 correct (78.42)\n",
      "skip model saving\n",
      "[45,   200] loss: 0.069054\n",
      "[45,   400] loss: 0.064882\n",
      "Got 3125 / 4000 correct (78.12)\n",
      "skip model saving\n",
      "[46,   200] loss: 0.064221\n",
      "[46,   400] loss: 0.096250\n",
      "Got 3061 / 4000 correct (76.53)\n",
      "skip model saving\n",
      "[47,   200] loss: 0.061081\n",
      "[47,   400] loss: 0.073400\n",
      "Got 3132 / 4000 correct (78.30)\n",
      "skip model saving\n",
      "[48,   200] loss: 0.073345\n",
      "[48,   400] loss: 0.071793\n",
      "Got 3107 / 4000 correct (77.68)\n",
      "skip model saving\n",
      "[49,   200] loss: 0.052701\n",
      "[49,   400] loss: 0.066782\n",
      "Got 3080 / 4000 correct (77.00)\n",
      "skip model saving\n",
      "[50,   200] loss: 0.076791\n",
      "[50,   400] loss: 0.065468\n",
      "Got 3120 / 4000 correct (78.00)\n",
      "skip model saving\n",
      "[51,   200] loss: 0.050815\n",
      "[51,   400] loss: 0.065811\n",
      "Got 3133 / 4000 correct (78.33)\n",
      "skip model saving\n",
      "[52,   200] loss: 0.081223\n",
      "[52,   400] loss: 0.083184\n",
      "Got 3078 / 4000 correct (76.95)\n",
      "skip model saving\n",
      "[53,   200] loss: 0.056044\n",
      "[53,   400] loss: 0.064051\n",
      "Got 3101 / 4000 correct (77.53)\n",
      "skip model saving\n",
      "[54,   200] loss: 0.052999\n",
      "[54,   400] loss: 0.072707\n",
      "Got 3161 / 4000 correct (79.03)\n",
      "saving model\n",
      "[55,   200] loss: 0.055477\n",
      "[55,   400] loss: 0.070508\n",
      "Got 3073 / 4000 correct (76.83)\n",
      "skip model saving\n",
      "[56,   200] loss: 0.054369\n",
      "[56,   400] loss: 0.075714\n",
      "Got 3078 / 4000 correct (76.95)\n",
      "skip model saving\n",
      "[57,   200] loss: 0.066431\n",
      "[57,   400] loss: 0.073899\n",
      "Got 3114 / 4000 correct (77.85)\n",
      "skip model saving\n",
      "[58,   200] loss: 0.050502\n",
      "[58,   400] loss: 0.043625\n",
      "Got 3141 / 4000 correct (78.53)\n",
      "skip model saving\n",
      "[59,   200] loss: 0.046828\n",
      "[59,   400] loss: 0.094790\n",
      "Got 3154 / 4000 correct (78.85)\n",
      "skip model saving\n",
      "[60,   200] loss: 0.044328\n",
      "[60,   400] loss: 0.054772\n",
      "Got 3107 / 4000 correct (77.68)\n",
      "skip model saving\n",
      "[61,   200] loss: 0.032795\n",
      "[61,   400] loss: 0.048995\n",
      "Got 3066 / 4000 correct (76.65)\n",
      "skip model saving\n",
      "[62,   200] loss: 0.070098\n",
      "[62,   400] loss: 0.066603\n",
      "Got 3125 / 4000 correct (78.12)\n",
      "skip model saving\n",
      "[63,   200] loss: 0.041618\n",
      "[63,   400] loss: 0.060678\n",
      "Got 3119 / 4000 correct (77.98)\n",
      "skip model saving\n",
      "[64,   200] loss: 0.044437\n",
      "[64,   400] loss: 0.065311\n",
      "Got 3078 / 4000 correct (76.95)\n",
      "skip model saving\n",
      "[65,   200] loss: 0.051217\n",
      "[65,   400] loss: 0.049175\n",
      "Got 3124 / 4000 correct (78.10)\n",
      "skip model saving\n",
      "[66,   200] loss: 0.047519\n",
      "[66,   400] loss: 0.055744\n",
      "Got 3145 / 4000 correct (78.62)\n",
      "skip model saving\n",
      "[67,   200] loss: 0.040021\n",
      "[67,   400] loss: 0.049807\n",
      "Got 3095 / 4000 correct (77.38)\n",
      "skip model saving\n",
      "[68,   200] loss: 0.040585\n",
      "[68,   400] loss: 0.042737\n",
      "Got 3082 / 4000 correct (77.05)\n",
      "skip model saving\n",
      "[69,   200] loss: 0.053803\n",
      "[69,   400] loss: 0.055141\n",
      "Got 3113 / 4000 correct (77.83)\n",
      "skip model saving\n",
      "[70,   200] loss: 0.048435\n",
      "[70,   400] loss: 0.048843\n",
      "Got 3169 / 4000 correct (79.22)\n",
      "saving model\n",
      "[71,   200] loss: 0.043475\n",
      "[71,   400] loss: 0.055368\n",
      "Got 3153 / 4000 correct (78.83)\n",
      "skip model saving\n",
      "[72,   200] loss: 0.037416\n",
      "[72,   400] loss: 0.049263\n",
      "Got 3094 / 4000 correct (77.35)\n",
      "skip model saving\n",
      "[73,   200] loss: 0.041467\n",
      "[73,   400] loss: 0.049873\n",
      "Got 3178 / 4000 correct (79.45)\n",
      "saving model\n",
      "[74,   200] loss: 0.037778\n",
      "[74,   400] loss: 0.032708\n",
      "Got 3092 / 4000 correct (77.30)\n",
      "skip model saving\n",
      "[75,   200] loss: 0.052441\n",
      "[75,   400] loss: 0.053779\n",
      "Got 3124 / 4000 correct (78.10)\n",
      "skip model saving\n",
      "[76,   200] loss: 0.033809\n",
      "[76,   400] loss: 0.064182\n",
      "Got 3113 / 4000 correct (77.83)\n",
      "skip model saving\n",
      "[77,   200] loss: 0.040395\n",
      "[77,   400] loss: 0.045860\n",
      "Got 3135 / 4000 correct (78.38)\n",
      "skip model saving\n",
      "[78,   200] loss: 0.030420\n",
      "[78,   400] loss: 0.027607\n",
      "Got 3111 / 4000 correct (77.78)\n",
      "skip model saving\n",
      "[79,   200] loss: 0.040802\n",
      "[79,   400] loss: 0.054775\n",
      "Got 3119 / 4000 correct (77.98)\n",
      "skip model saving\n",
      "[80,   200] loss: 0.054428\n",
      "[80,   400] loss: 0.037889\n",
      "Got 3096 / 4000 correct (77.40)\n",
      "skip model saving\n",
      "[81,   200] loss: 0.024205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[81,   400] loss: 0.011513\n",
      "Got 3207 / 4000 correct (80.17)\n",
      "saving model\n",
      "[82,   200] loss: 0.003996\n",
      "[82,   400] loss: 0.004698\n",
      "Got 3202 / 4000 correct (80.05)\n",
      "skip model saving\n",
      "[83,   200] loss: 0.001916\n",
      "[83,   400] loss: 0.001921\n",
      "Got 3212 / 4000 correct (80.30)\n",
      "saving model\n",
      "[84,   200] loss: 0.001840\n",
      "[84,   400] loss: 0.001312\n",
      "Got 3211 / 4000 correct (80.27)\n",
      "skip model saving\n",
      "[85,   200] loss: 0.000876\n",
      "[85,   400] loss: 0.000730\n",
      "Got 3226 / 4000 correct (80.65)\n",
      "saving model\n",
      "[86,   200] loss: 0.000743\n",
      "[86,   400] loss: 0.001804\n",
      "Got 3230 / 4000 correct (80.75)\n",
      "saving model\n",
      "[87,   200] loss: 0.000689\n",
      "[87,   400] loss: 0.000952\n",
      "Got 3224 / 4000 correct (80.60)\n",
      "skip model saving\n",
      "[88,   200] loss: 0.000429\n",
      "[88,   400] loss: 0.000594\n",
      "Got 3219 / 4000 correct (80.47)\n",
      "skip model saving\n",
      "[89,   200] loss: 0.000381\n",
      "[89,   400] loss: 0.000650\n",
      "Got 3216 / 4000 correct (80.40)\n",
      "skip model saving\n",
      "[90,   200] loss: 0.000876\n",
      "[90,   400] loss: 0.000549\n",
      "Got 3232 / 4000 correct (80.80)\n",
      "saving model\n",
      "[91,   200] loss: 0.000583\n",
      "[91,   400] loss: 0.000353\n",
      "Got 3237 / 4000 correct (80.92)\n",
      "saving model\n",
      "[92,   200] loss: 0.000842\n",
      "[92,   400] loss: 0.000645\n",
      "Got 3209 / 4000 correct (80.23)\n",
      "skip model saving\n",
      "[93,   200] loss: 0.000350\n",
      "[93,   400] loss: 0.000216\n",
      "Got 3243 / 4000 correct (81.08)\n",
      "saving model\n",
      "[94,   200] loss: 0.000209\n",
      "[94,   400] loss: 0.000152\n",
      "Got 3225 / 4000 correct (80.62)\n",
      "skip model saving\n",
      "[95,   200] loss: 0.000474\n",
      "[95,   400] loss: 0.000252\n",
      "Got 3233 / 4000 correct (80.83)\n",
      "skip model saving\n",
      "[96,   200] loss: 0.000184\n",
      "[96,   400] loss: 0.000106\n",
      "Got 3228 / 4000 correct (80.70)\n",
      "skip model saving\n",
      "[97,   200] loss: 0.000549\n",
      "[97,   400] loss: 0.001831\n",
      "Got 3207 / 4000 correct (80.17)\n",
      "skip model saving\n",
      "[98,   200] loss: 0.000525\n",
      "[98,   400] loss: 0.000329\n",
      "Got 3207 / 4000 correct (80.17)\n",
      "skip model saving\n",
      "[99,   200] loss: 0.000486\n",
      "[99,   400] loss: 0.000275\n",
      "Got 3204 / 4000 correct (80.10)\n",
      "skip model saving\n",
      "[100,   200] loss: 0.000373\n",
      "[100,   400] loss: 0.000218\n",
      "Got 3200 / 4000 correct (80.00)\n",
      "skip model saving\n",
      "[101,   200] loss: 0.000266\n",
      "[101,   400] loss: 0.000452\n",
      "Got 3205 / 4000 correct (80.12)\n",
      "skip model saving\n",
      "[102,   200] loss: 0.000947\n",
      "[102,   400] loss: 0.000832\n",
      "Got 3203 / 4000 correct (80.08)\n",
      "skip model saving\n",
      "[103,   200] loss: 0.000545\n",
      "[103,   400] loss: 0.000784\n",
      "Got 3197 / 4000 correct (79.92)\n",
      "skip model saving\n",
      "[104,   200] loss: 0.000167\n",
      "[104,   400] loss: 0.000204\n",
      "Got 3212 / 4000 correct (80.30)\n",
      "skip model saving\n",
      "[105,   200] loss: 0.000118\n",
      "[105,   400] loss: 0.000459\n",
      "Got 3209 / 4000 correct (80.23)\n",
      "skip model saving\n",
      "[106,   200] loss: 0.001087\n",
      "[106,   400] loss: 0.000565\n",
      "Got 3222 / 4000 correct (80.55)\n",
      "skip model saving\n",
      "[107,   200] loss: 0.000300\n",
      "[107,   400] loss: 0.000361\n",
      "Got 3229 / 4000 correct (80.73)\n",
      "skip model saving\n",
      "[108,   200] loss: 0.000124\n",
      "[108,   400] loss: 0.000337\n",
      "Got 3204 / 4000 correct (80.10)\n",
      "skip model saving\n",
      "[109,   200] loss: 0.000371\n",
      "[109,   400] loss: 0.000124\n",
      "Got 3219 / 4000 correct (80.47)\n",
      "skip model saving\n",
      "[110,   200] loss: 0.000160\n",
      "[110,   400] loss: 0.000061\n",
      "Got 3222 / 4000 correct (80.55)\n",
      "skip model saving\n",
      "[111,   200] loss: 0.000406\n",
      "[111,   400] loss: 0.000294\n",
      "Got 3212 / 4000 correct (80.30)\n",
      "skip model saving\n",
      "[112,   200] loss: 0.000090\n",
      "[112,   400] loss: 0.001248\n",
      "Got 3226 / 4000 correct (80.65)\n",
      "skip model saving\n",
      "[113,   200] loss: 0.000200\n",
      "[113,   400] loss: 0.000375\n",
      "Got 3223 / 4000 correct (80.58)\n",
      "skip model saving\n",
      "[114,   200] loss: 0.000287\n",
      "[114,   400] loss: 0.000385\n",
      "Got 3195 / 4000 correct (79.88)\n",
      "skip model saving\n",
      "[115,   200] loss: 0.000928\n",
      "[115,   400] loss: 0.000201\n",
      "Got 3219 / 4000 correct (80.47)\n",
      "skip model saving\n",
      "[116,   200] loss: 0.000270\n",
      "[116,   400] loss: 0.000395\n",
      "Got 3213 / 4000 correct (80.33)\n",
      "skip model saving\n",
      "[117,   200] loss: 0.000367\n",
      "[117,   400] loss: 0.000131\n",
      "Got 3217 / 4000 correct (80.42)\n",
      "skip model saving\n",
      "[118,   200] loss: 0.000271\n",
      "[118,   400] loss: 0.000208\n",
      "Got 3231 / 4000 correct (80.77)\n",
      "skip model saving\n",
      "[119,   200] loss: 0.000113\n",
      "[119,   400] loss: 0.000051\n",
      "Got 3239 / 4000 correct (80.97)\n",
      "skip model saving\n",
      "[120,   200] loss: 0.000210\n",
      "[120,   400] loss: 0.000086\n",
      "Got 3199 / 4000 correct (79.97)\n",
      "skip model saving\n",
      "[121,   200] loss: 0.001097\n",
      "[121,   400] loss: 0.000595\n",
      "Got 3210 / 4000 correct (80.25)\n",
      "skip model saving\n",
      "[122,   200] loss: 0.000148\n",
      "[122,   400] loss: 0.000214\n",
      "Got 3213 / 4000 correct (80.33)\n",
      "skip model saving\n",
      "[123,   200] loss: 0.000258\n",
      "[123,   400] loss: 0.000057\n",
      "Got 3217 / 4000 correct (80.42)\n",
      "skip model saving\n",
      "[124,   200] loss: 0.000127\n",
      "[124,   400] loss: 0.000076\n",
      "Got 3217 / 4000 correct (80.42)\n",
      "skip model saving\n",
      "[125,   200] loss: 0.000313\n",
      "[125,   400] loss: 0.000071\n",
      "Got 3216 / 4000 correct (80.40)\n",
      "skip model saving\n",
      "[126,   200] loss: 0.000278\n",
      "[126,   400] loss: 0.000127\n",
      "Got 3220 / 4000 correct (80.50)\n",
      "skip model saving\n",
      "[127,   200] loss: 0.000408\n",
      "[127,   400] loss: 0.000046\n",
      "Got 3229 / 4000 correct (80.73)\n",
      "skip model saving\n",
      "[128,   200] loss: 0.000037\n",
      "[128,   400] loss: 0.000078\n",
      "Got 3222 / 4000 correct (80.55)\n",
      "skip model saving\n",
      "[129,   200] loss: 0.000016\n",
      "[129,   400] loss: 0.000119\n",
      "Got 3228 / 4000 correct (80.70)\n",
      "skip model saving\n",
      "[130,   200] loss: 0.000136\n",
      "[130,   400] loss: 0.000039\n",
      "Got 3228 / 4000 correct (80.70)\n",
      "skip model saving\n",
      "[131,   200] loss: 0.000182\n",
      "[131,   400] loss: 0.000023\n",
      "Got 3232 / 4000 correct (80.80)\n",
      "skip model saving\n",
      "[132,   200] loss: 0.000023\n",
      "[132,   400] loss: 0.000029\n",
      "Got 3219 / 4000 correct (80.47)\n",
      "skip model saving\n",
      "[133,   200] loss: 0.000024\n",
      "[133,   400] loss: 0.000029\n",
      "Got 3222 / 4000 correct (80.55)\n",
      "skip model saving\n",
      "[134,   200] loss: 0.000036\n",
      "[134,   400] loss: 0.000044\n",
      "Got 3230 / 4000 correct (80.75)\n",
      "skip model saving\n",
      "[135,   200] loss: 0.000066\n",
      "[135,   400] loss: 0.000073\n",
      "Got 3223 / 4000 correct (80.58)\n",
      "skip model saving\n",
      "[136,   200] loss: 0.000030\n",
      "[136,   400] loss: 0.000042\n",
      "Got 3224 / 4000 correct (80.60)\n",
      "skip model saving\n",
      "[137,   200] loss: 0.000335\n",
      "[137,   400] loss: 0.000037\n",
      "Got 3233 / 4000 correct (80.83)\n",
      "skip model saving\n",
      "[138,   200] loss: 0.000090\n",
      "[138,   400] loss: 0.000024\n",
      "Got 3224 / 4000 correct (80.60)\n",
      "skip model saving\n",
      "[139,   200] loss: 0.000023\n",
      "[139,   400] loss: 0.000125\n",
      "Got 3222 / 4000 correct (80.55)\n",
      "skip model saving\n",
      "[140,   200] loss: 0.000049\n",
      "[140,   400] loss: 0.000017\n",
      "Got 3227 / 4000 correct (80.67)\n",
      "skip model saving\n",
      "[141,   200] loss: 0.000020\n",
      "[141,   400] loss: 0.000029\n",
      "Got 3231 / 4000 correct (80.77)\n",
      "skip model saving\n",
      "[142,   200] loss: 0.000048\n",
      "[142,   400] loss: 0.000070\n",
      "Got 3237 / 4000 correct (80.92)\n",
      "skip model saving\n",
      "[143,   200] loss: 0.000021\n",
      "[143,   400] loss: 0.000040\n",
      "Got 3236 / 4000 correct (80.90)\n",
      "skip model saving\n",
      "[144,   200] loss: 0.000009\n",
      "[144,   400] loss: 0.000041\n",
      "Got 3234 / 4000 correct (80.85)\n",
      "skip model saving\n",
      "[145,   200] loss: 0.000015\n",
      "[145,   400] loss: 0.000035\n",
      "Got 3230 / 4000 correct (80.75)\n",
      "skip model saving\n",
      "[146,   200] loss: 0.000011\n",
      "[146,   400] loss: 0.000022\n",
      "Got 3247 / 4000 correct (81.17)\n",
      "saving model\n",
      "[147,   200] loss: 0.000017\n",
      "[147,   400] loss: 0.000028\n",
      "Got 3227 / 4000 correct (80.67)\n",
      "skip model saving\n",
      "[148,   200] loss: 0.000015\n",
      "[148,   400] loss: 0.000043\n",
      "Got 3234 / 4000 correct (80.85)\n",
      "skip model saving\n",
      "[149,   200] loss: 0.000018\n",
      "[149,   400] loss: 0.000018\n",
      "Got 3244 / 4000 correct (81.10)\n",
      "skip model saving\n",
      "[150,   200] loss: 0.000012\n",
      "[150,   400] loss: 0.000048\n",
      "Got 3230 / 4000 correct (80.75)\n",
      "skip model saving\n",
      "[151,   200] loss: 0.000033\n",
      "[151,   400] loss: 0.000070\n",
      "Got 3234 / 4000 correct (80.85)\n",
      "skip model saving\n",
      "[152,   200] loss: 0.000389\n",
      "[152,   400] loss: 0.000011\n",
      "Got 3238 / 4000 correct (80.95)\n",
      "skip model saving\n",
      "[153,   200] loss: 0.000052\n",
      "[153,   400] loss: 0.000017\n",
      "Got 3233 / 4000 correct (80.83)\n",
      "skip model saving\n",
      "[154,   200] loss: 0.000014\n",
      "[154,   400] loss: 0.000011\n",
      "Got 3235 / 4000 correct (80.88)\n",
      "skip model saving\n",
      "[155,   200] loss: 0.000022\n",
      "[155,   400] loss: 0.000018\n",
      "Got 3236 / 4000 correct (80.90)\n",
      "skip model saving\n",
      "[156,   200] loss: 0.000021\n",
      "[156,   400] loss: 0.000028\n",
      "Got 3236 / 4000 correct (80.90)\n",
      "skip model saving\n",
      "[157,   200] loss: 0.000011\n",
      "[157,   400] loss: 0.000030\n",
      "Got 3225 / 4000 correct (80.62)\n",
      "skip model saving\n",
      "[158,   200] loss: 0.000009\n",
      "[158,   400] loss: 0.000022\n",
      "Got 3240 / 4000 correct (81.00)\n",
      "skip model saving\n",
      "[159,   200] loss: 0.000016\n",
      "[159,   400] loss: 0.000014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 3226 / 4000 correct (80.65)\n",
      "skip model saving\n",
      "[160,   200] loss: 0.000016\n",
      "[160,   400] loss: 0.000012\n",
      "Got 3227 / 4000 correct (80.67)\n",
      "skip model saving\n",
      "[161,   200] loss: 0.000015\n",
      "[161,   400] loss: 0.000014\n",
      "Got 3231 / 4000 correct (80.77)\n",
      "skip model saving\n",
      "[162,   200] loss: 0.000018\n",
      "[162,   400] loss: 0.000023\n",
      "Got 3227 / 4000 correct (80.67)\n",
      "skip model saving\n",
      "[163,   200] loss: 0.000010\n",
      "[163,   400] loss: 0.000017\n",
      "Got 3237 / 4000 correct (80.92)\n",
      "skip model saving\n",
      "[164,   200] loss: 0.000008\n",
      "[164,   400] loss: 0.000011\n",
      "Got 3240 / 4000 correct (81.00)\n",
      "skip model saving\n",
      "[165,   200] loss: 0.000033\n",
      "[165,   400] loss: 0.000040\n",
      "Got 3232 / 4000 correct (80.80)\n",
      "skip model saving\n",
      "[166,   200] loss: 0.000006\n",
      "[166,   400] loss: 0.000016\n",
      "Got 3228 / 4000 correct (80.70)\n",
      "skip model saving\n",
      "[167,   200] loss: 0.000011\n",
      "[167,   400] loss: 0.000013\n",
      "Got 3236 / 4000 correct (80.90)\n",
      "skip model saving\n",
      "[168,   200] loss: 0.000013\n",
      "[168,   400] loss: 0.000013\n",
      "Got 3240 / 4000 correct (81.00)\n",
      "skip model saving\n",
      "[169,   200] loss: 0.000011\n",
      "[169,   400] loss: 0.000081\n",
      "Got 3232 / 4000 correct (80.80)\n",
      "skip model saving\n",
      "[170,   200] loss: 0.000037\n",
      "[170,   400] loss: 0.000013\n",
      "Got 3237 / 4000 correct (80.92)\n",
      "skip model saving\n",
      "[171,   200] loss: 0.000010\n",
      "[171,   400] loss: 0.000010\n",
      "Got 3230 / 4000 correct (80.75)\n",
      "skip model saving\n",
      "[172,   200] loss: 0.000425\n",
      "[172,   400] loss: 0.000011\n",
      "Got 3233 / 4000 correct (80.83)\n",
      "skip model saving\n",
      "[173,   200] loss: 0.000020\n",
      "[173,   400] loss: 0.000012\n",
      "Got 3237 / 4000 correct (80.92)\n",
      "skip model saving\n",
      "[174,   200] loss: 0.000010\n",
      "[174,   400] loss: 0.000013\n",
      "Got 3234 / 4000 correct (80.85)\n",
      "skip model saving\n",
      "[175,   200] loss: 0.000018\n",
      "[175,   400] loss: 0.000051\n",
      "Got 3233 / 4000 correct (80.83)\n",
      "skip model saving\n",
      "[176,   200] loss: 0.000015\n",
      "[176,   400] loss: 0.000013\n",
      "Got 3230 / 4000 correct (80.75)\n",
      "skip model saving\n",
      "[177,   200] loss: 0.000038\n",
      "[177,   400] loss: 0.000021\n",
      "Got 3237 / 4000 correct (80.92)\n",
      "skip model saving\n",
      "[178,   200] loss: 0.000017\n",
      "[178,   400] loss: 0.000007\n",
      "Got 3230 / 4000 correct (80.75)\n",
      "skip model saving\n",
      "[179,   200] loss: 0.000019\n",
      "[179,   400] loss: 0.000007\n",
      "Got 3228 / 4000 correct (80.70)\n",
      "skip model saving\n",
      "[180,   200] loss: 0.000018\n",
      "[180,   400] loss: 0.000066\n",
      "Got 3235 / 4000 correct (80.88)\n",
      "skip model saving\n",
      "[181,   200] loss: 0.000013\n",
      "[181,   400] loss: 0.000008\n",
      "Got 3237 / 4000 correct (80.92)\n",
      "skip model saving\n",
      "[182,   200] loss: 0.000065\n",
      "[182,   400] loss: 0.000037\n",
      "Got 3234 / 4000 correct (80.85)\n",
      "skip model saving\n",
      "[183,   200] loss: 0.000016\n",
      "[183,   400] loss: 0.000008\n",
      "Got 3232 / 4000 correct (80.80)\n",
      "skip model saving\n",
      "[184,   200] loss: 0.000015\n",
      "[184,   400] loss: 0.000195\n",
      "Got 3223 / 4000 correct (80.58)\n",
      "skip model saving\n",
      "[185,   200] loss: 0.000010\n",
      "[185,   400] loss: 0.000011\n",
      "Got 3236 / 4000 correct (80.90)\n",
      "skip model saving\n",
      "[186,   200] loss: 0.000026\n",
      "[186,   400] loss: 0.000025\n",
      "Got 3229 / 4000 correct (80.73)\n",
      "skip model saving\n",
      "[187,   200] loss: 0.000012\n",
      "[187,   400] loss: 0.000020\n",
      "Got 3236 / 4000 correct (80.90)\n",
      "skip model saving\n",
      "[188,   200] loss: 0.000096\n",
      "[188,   400] loss: 0.000010\n",
      "Got 3232 / 4000 correct (80.80)\n",
      "skip model saving\n",
      "[189,   200] loss: 0.000122\n",
      "[189,   400] loss: 0.000019\n",
      "Got 3235 / 4000 correct (80.88)\n",
      "skip model saving\n",
      "[190,   200] loss: 0.000016\n",
      "[190,   400] loss: 0.000010\n",
      "Got 3235 / 4000 correct (80.88)\n",
      "skip model saving\n",
      "[191,   200] loss: 0.000026\n",
      "[191,   400] loss: 0.000010\n",
      "Got 3241 / 4000 correct (81.03)\n",
      "skip model saving\n",
      "[192,   200] loss: 0.000009\n",
      "[192,   400] loss: 0.000022\n",
      "Got 3233 / 4000 correct (80.83)\n",
      "skip model saving\n",
      "[193,   200] loss: 0.000012\n",
      "[193,   400] loss: 0.000047\n",
      "Got 3229 / 4000 correct (80.73)\n",
      "skip model saving\n",
      "[194,   200] loss: 0.000030\n",
      "[194,   400] loss: 0.000015\n",
      "Got 3232 / 4000 correct (80.80)\n",
      "skip model saving\n",
      "[195,   200] loss: 0.000023\n",
      "[195,   400] loss: 0.000007\n",
      "Got 3231 / 4000 correct (80.77)\n",
      "skip model saving\n",
      "[196,   200] loss: 0.000011\n",
      "[196,   400] loss: 0.000011\n",
      "Got 3231 / 4000 correct (80.77)\n",
      "skip model saving\n",
      "[197,   200] loss: 0.000014\n",
      "[197,   400] loss: 0.000013\n",
      "Got 3233 / 4000 correct (80.83)\n",
      "skip model saving\n",
      "[198,   200] loss: 0.000016\n",
      "[198,   400] loss: 0.000010\n",
      "Got 3240 / 4000 correct (81.00)\n",
      "skip model saving\n",
      "[199,   200] loss: 0.000008\n",
      "[199,   400] loss: 0.000008\n",
      "Got 3231 / 4000 correct (80.77)\n",
      "skip model saving\n",
      "[200,   200] loss: 0.000008\n",
      "[200,   400] loss: 0.000012\n",
      "Got 3237 / 4000 correct (80.92)\n",
      "skip model saving\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "# define and train the network\n",
    "vanilla_model_path = './cifar32_model.pth'\n",
    "vanilla_model = ResNet50()\n",
    "lr=0.1\n",
    "vanilla_optimizer = optim.Adam(vanilla_model.parameters(), lr=lr)\n",
    "vanilla_lr_scheduler = optim.lr_scheduler.MultiStepLR(vanilla_optimizer, milestones=[100, 150, 180])\n",
    "train_part(vanilla_model, data_loader_train, data_loader_val, vanilla_model_path, vanilla_optimizer, vanilla_lr_scheduler, epochs = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Normal CIFAR10 on Vanilla ResNet50\n",
    "\n",
    "The below code tests the vanilla ResNet50 model on the normal CIFAR10 test set and prints out the final accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 8124 / 10000 correct, accuracy of the dataset is: 81.240 %\n"
     ]
    }
   ],
   "source": [
    "# report test set accuracy\n",
    "vanilla_model = ResNet50()\n",
    "vanilla_model.load_state_dict(torch.load('./cifar32_model.pth'))\n",
    "vanilla_model.to(device)\n",
    "check_accuracy(data_loader_test, vanilla_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stylised ResNet50 Training\n",
    "\n",
    "Stylised ResNet50 training has all the same settings as vanilla ResNet50, except the data being used here are the stylised CIFAR10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()\n",
    "\n",
    "# # define and train the network\n",
    "# stylised_model_path = './cifar32_style_model.pth'\n",
    "# stylised_model = ResNet50()\n",
    "# lr=0.1\n",
    "# stylised_optimizer = optim.Adam(stylised_model.parameters(), lr=lr)\n",
    "# stylised_lr_scheduler = optim.lr_scheduler.MultiStepLR(stylised_optimizer, milestones=[80, 120, 150, 180])\n",
    "# train_part(stylised_model, data_loader_train_style, data_loader_val_style, stylised_model_path, stylised_optimizer, stylised_lr_scheduler, epochs = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Stylised CIFAR10 on Stylised ResNet50\n",
    "\n",
    "The below code tests the stylised ResNet50 model on the stylised CIFAR10 test set and prints out the final accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # report test set accuracy\n",
    "# stylised_model = ResNet50()\n",
    "# stylised_model.load_state_dict(torch.load('./cifar32_style_model.pth'))\n",
    "# stylised_model.to(device)\n",
    "# check_accuracy(data_loader_test_style, stylised_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Stylised CIFAR10 on Vanilla ResNet50\n",
    "\n",
    "The below code tests the vanilla ResNet50 model on the stylised CIFAR10 test set and prints out the final accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1108 / 10000 correct, accuracy of the dataset is: 11.080 %\n"
     ]
    }
   ],
   "source": [
    "# report test set accuracy\n",
    "vanilla_model = ResNet50()\n",
    "vanilla_model.load_state_dict(torch.load('./cifar32_model.pth'))\n",
    "vanilla_model.to(device)\n",
    "check_accuracy(data_loader_test_style, vanilla_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Vanilla CIFAR10 on Stylised ResNet50\n",
    "\n",
    "The below code tests the stylised ResNet50 model on the vanilla CIFAR10 test set and prints out the final accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # report test set accuracy\n",
    "# stylised_model = ResNet50()\n",
    "# stylised_model.load_state_dict(torch.load('./cifar32_style_model.pth'))\n",
    "# stylised_model.to(device)\n",
    "# check_accuracy(data_loader_test, stylised_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1001 / 10000 correct, accuracy of the dataset is: 10.010 %\n"
     ]
    }
   ],
   "source": [
    "# report test set accuracy\n",
    "vanilla_model = ResNet50()\n",
    "vanilla_model.load_state_dict(torch.load('./cifar32_model.pth'))\n",
    "vanilla_model.to(device)\n",
    "check_accuracy(data_loader_test_style_red, vanilla_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
